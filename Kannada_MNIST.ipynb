{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils import data\nimport torchvision\n\nimport matplotlib.pyplot as plt\n\nTRAIN = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if TRAIN:\n    train = pd.read_csv('../input/Kannada-MNIST/train.csv').to_numpy()\n\n    X_train, y_train = train[:, 1:], train[:, 0]\n    X_train, y_train = torch.tensor(X_train).to(torch.float), torch.tensor(y_train)\n    dset_train = data.TensorDataset(X_train.reshape(-1, 1, 28, 28), y_train)\n\n    factor = 0.9\n    train_len = int(len(dset_train) * factor)\n    valid_len = len(dset_train)  - train_len\n\n    dset_train, dset_valid = data.random_split(dset_train, [train_len, valid_len])\n\n    batch_size = 16\n\n    dloader_train = data.DataLoader(dset_train, batch_size=batch_size, shuffle=True)\n    dloader_valid = data.DataLoader(dset_valid, batch_size=batch_size, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if TRAIN:\n    x, y = next(iter(dloader_train))\n    plt.imshow(torchvision.utils.make_grid(x).numpy().transpose(1, 2, 0))\n    print(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    '''\n    Convolutional part\n    conv -> relu -> pool -> dropout\n    FC part\n    fc -> relu'''\n    def __init__(self):\n        super(Model, self).__init__()\n        \n        self.conv1 = nn.Conv2d(1, 16, 3,   padding=1)   \n        self.conv2 = nn.Conv2d(16, 32, 3,  padding=1)\n        self.conv3 = nn.Conv2d(32, 64, 3,  padding=1)\n        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n        \n        self.pool = nn.MaxPool2d(2)\n    \n        self.bn1 = nn.BatchNorm2d(16)\n        self.bn2 = nn.BatchNorm2d(32)\n        self.bn3 = nn.BatchNorm2d(64)\n        self.bn4 = nn.BatchNorm2d(128)\n        \n        self.dropout = nn.Dropout(0.25)\n        \n        self.fc1 = nn.Linear(128 * 7**2, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n        \n    def forward(self, x):\n        x = F.leaky_relu(self.bn1(self.conv1(x)), 0.1)\n        x = F.leaky_relu(self.bn2(self.conv2(x)), 0.1)\n        x = self.pool(x)\n        x = F.leaky_relu(self.bn3(self.conv3(x)), 0.1)\n        x = F.leaky_relu(self.bn4(self.conv4(x)), 0.1)\n        x = self.pool(x)\n        \n        x = x.view(x.size(0), -1)\n        \n        x = F.relu(self.dropout(self.fc1(x)))\n        x = self.fc2(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if TRAIN:\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    model = Model().to(device)\n    ℓ_fn = nn.CrossEntropyLoss()\n    lr = 0.001\n    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n    epochs = 20\n    for i_epoch in range(1, epochs+1):\n        for x, y in dloader_train:\n            x, y = x.to(device), y.to(device)\n            ŷ = model(x)\n            ℓ = ℓ_fn(ŷ, y)\n            optimizer.zero_grad()\n            ℓ.backward()\n            optimizer.step()\n        model.eval()\n        loss_val = []\n        loss_acc = []\n        for x, y in dloader_train:\n            x, y = x.to(device), y.to(device)\n            ŷ = model(x)\n            ℓ = ℓ_fn(ŷ, y)\n            loss_val.append(ℓ.item())\n            loss_acc.append((y == ŷ.argmax(dim=1)).to(torch.float).mean())\n        model.train()\n        print(f'Epoch {i_epoch} loss: {sum(loss_val)/len(loss_val):.3f}, aacuracy: {sum(loss_acc)/len(loss_acc):.4f}')\n    torch.save(model.state_dict(), 'model.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test dataset\ntest = pd.read_csv('../input/Kannada-MNIST/test.csv').to_numpy()\nX_test, X_id = test[:, 1:], test[:, 0]\nX_test, X_id = torch.tensor(X_test).to(torch.float), torch.tensor(X_id)\ndset_test = data.TensorDataset(X_test.reshape(-1, 1, 28, 28), X_id)\ndloader_test = data.DataLoader(dset_test, batch_size=len(dset_test), shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Model()\nmodel.cpu()\nmodel.load_state_dict(torch.load('../input/trained-model-kannada/model.pt',\n                                 map_location=torch.device('cpu')))\n\nmodel.eval()\nx, x_id = next(iter(dloader_test))\nŷ = model(x)\nmodel.train()\n\nsubmission  = pd.DataFrame({'id': x_id, 'label': ŷ.argmax(dim=1)})\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}